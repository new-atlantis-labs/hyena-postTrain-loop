{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff27cf2c-a5ea-4153-91cd-d746e9508ce9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU pip\n",
    "%pip install -qU sagemaker boto3 awscli boto3 ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c328e9e8-47e3-4409-8f33-ae25acf2491c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys\n",
    "from time import strftime\n",
    "from functools import partial\n",
    "import importlib\n",
    "\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.experiments.run import Run\n",
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.debugger import TensorBoardOutputConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4f1e52b1-580f-47d7-8615-1764741b8da5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2.233.0', '1.35.60')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sagemaker.__version__, boto3.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74fe67db-5ca7-404e-aae5-6c3b04d20920",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/SageMaker/notebooks\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea50d6b9-cc4a-43f8-a0a6-0976c6e71fdb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-11-13 22:00:12--  https://s3.amazonaws.com/mountpoint-s3-release/latest/x86_64/mount-s3.rpm\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 16.15.192.239, 52.217.235.56, 52.217.98.158, ...\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|16.15.192.239|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12266864 (12M) [binary/octet-stream]\n",
      "Saving to: ‘/home/ec2-user/mount-s3.rpm’\n",
      "\n",
      "100%[======================================>] 12,266,864  13.2MB/s   in 0.9s   \n",
      "\n",
      "2024-11-13 22:00:13 (13.2 MB/s) - ‘/home/ec2-user/mount-s3.rpm’ saved [12266864/12266864]\n",
      "\n",
      "package mount-s3 is not installed\n",
      "Loaded plugins: dkms-build-requires, extras_suggestions, kernel-livepatch,\n",
      "              : langpacks, priorities, update-motd, versionlock\n",
      "Examining /home/ec2-user/mount-s3.rpm: mount-s3-1.10.0-1.x86_64\n",
      "Marking /home/ec2-user/mount-s3.rpm to be installed\n",
      "Resolving Dependencies\n",
      "--> Running transaction check\n",
      "---> Package mount-s3.x86_64 0:1.10.0-1 will be installed\n",
      "--> Processing Dependency: fuse for package: mount-s3-1.10.0-1.x86_64\n",
      "amzn2-core                                               | 3.6 kB     00:00     \n",
      "amzn2extra-docker                                        | 2.9 kB     00:00     \n",
      "amzn2extra-kernel-5.10                                   | 3.0 kB     00:00     \n",
      "amzn2extra-livepatch                                     | 2.9 kB     00:00     \n",
      "amzn2extra-lustre                                        | 2.5 kB     00:00     \n",
      "amzn2extra-python3.8                                     | 2.9 kB     00:00     \n",
      "centos-extras                                            | 2.9 kB     00:00     \n",
      "copr:copr.fedorainfracloud.org:vbatts:shadow-utils-newxi | 3.3 kB     00:00     \n",
      "https://download.docker.com/linux/centos/2/x86_64/stable/repodata/repomd.xml: [Errno 14] HTTPS Error 404 - Not Found\n",
      "Trying other mirror.\n",
      "nvidia-container-toolkit/x86_64/signature                |  833 B     00:00     \n",
      "nvidia-container-toolkit/x86_64/signature                | 2.1 kB     00:02 !!! \n",
      "(1/4): amzn2extra-kernel-5.10/2/x86_64/updateinfo          |  93 kB   00:00     \n",
      "(2/4): nvidia-container-toolkit/x86_64/primary             |  15 kB   00:00     \n",
      "(3/4): amzn2extra-docker/2/x86_64/primary_db               | 116 kB   00:00     \n",
      "(4/4): amzn2extra-kernel-5.10/2/x86_64/primary_db          |  32 MB   00:00     \n",
      "nvidia-container-toolkit                                                  99/99\n",
      "63 packages excluded due to repository priority protections\n",
      "--> Running transaction check\n",
      "---> Package fuse.x86_64 0:2.9.2-11.amzn2 will be installed\n",
      "--> Finished Dependency Resolution\n",
      "\n",
      "Dependencies Resolved\n",
      "\n",
      "================================================================================\n",
      " Package         Arch          Version                  Repository         Size\n",
      "================================================================================\n",
      "Installing:\n",
      " \u001b[1mmount-s3\u001b[m        x86_64        1.10.0-1                 /mount-s3          63 M\n",
      "Installing for dependencies:\n",
      " fuse            x86_64        2.9.2-11.amzn2           amzn2-core         86 k\n",
      "\n",
      "Transaction Summary\n",
      "================================================================================\n",
      "Install  1 Package (+1 Dependent package)\n",
      "\n",
      "Total size: 63 M\n",
      "Total download size: 86 k\n",
      "Installed size: 63 M\n",
      "Downloading packages:\n",
      "fuse-2.9.2-11.amzn2.x86_64.rpm                             |  86 kB   00:00     \n",
      "Running transaction check\n",
      "Running transaction test\n",
      "Transaction test succeeded\n",
      "Running transaction\n",
      "Warning: RPMDB altered outside of yum.\n",
      "  Installing : fuse-2.9.2-11.amzn2.x86_64                                   1/2 \n",
      "  Installing : mount-s3-1.10.0-1.x86_64                                     2/2 \n",
      "  Verifying  : mount-s3-1.10.0-1.x86_64                                     1/2 \n",
      "  Verifying  : fuse-2.9.2-11.amzn2.x86_64                                   2/2 \n",
      "\n",
      "Installed:\n",
      "  mount-s3.x86_64 0:1.10.0-1                                                    \n",
      "\n",
      "Dependency Installed:\n",
      "  fuse.x86_64 0:2.9.2-11.amzn2                                                  \n",
      "\n",
      "Complete!\n",
      "bucket newatlantis-raw-veba-db-prod is mounted at /home/ec2-user/SageMaker/s3/newatlantis-raw-veba-db-prod/\n"
     ]
    }
   ],
   "source": [
    "!bash ../scripts/mount_s3.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a62de69-d7e2-4da2-a79f-ec7ff8d87af9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 8\n",
      "drwxrwxr-x 2 ec2-user ec2-user 4096 Nov 13 22:00 .\n",
      "drwxrwxr-x 3 ec2-user ec2-user 4096 Nov 13 22:00 ..\n",
      "../s3/newatlantis-raw-veba-db-prod/.:\n",
      "total 8\n",
      "drwxrwxr-x 2 ec2-user ec2-user 4096 Nov 13 22:00 .\n",
      "drwxrwxr-x 3 ec2-user ec2-user 4096 Nov 13 22:00 ..\n",
      "\n",
      "../s3/newatlantis-raw-veba-db-prod/..:\n",
      "total 12\n",
      "drwxrwxr-x  3 ec2-user ec2-user 4096 Nov 13 22:00 .\n",
      "drwxr-xr-x 11 ec2-user ec2-user 4096 Nov 13 22:00 ..\n",
      "drwxrwxr-x  2 ec2-user ec2-user 4096 Nov 13 22:00 newatlantis-raw-veba-db-prod\n"
     ]
    }
   ],
   "source": [
    "# Check the mount point exists\n",
    "!ls -la ../s3/newatlantis-raw-veba-db-prod\n",
    "\n",
    "# Try listing with hidden files\n",
    "!ls -la ../s3/newatlantis-raw-veba-db-prod/.* 2>/dev/null\n",
    "\n",
    "# Check mount status\n",
    "!mount | grep s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fb25b02-b8a3-480e-a419-b29349c1ef19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           PRE MicroEuk_v3/\n",
      "                           PRE UniRef/\n",
      "                           PRE VDB_v5.1/\n",
      "                           PRE VDB_v7/\n",
      "                           PRE VDB_v8.1/\n",
      "                           PRE uncompressed/\n",
      "{\n",
      "    \"UserId\": \"AROAQYAUD2HFU3H3HHOAN:SageMaker\",\n",
      "    \"Account\": \"051581800907\",\n",
      "    \"Arn\": \"arn:aws:sts::051581800907:assumed-role/AmazonSageMaker-ExecutionRole-20240617T145283/SageMaker\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Check if you have read permissions\n",
    "!aws s3 ls s3://newatlantis-raw-veba-db-prod/\n",
    "\n",
    "# Check your AWS credentials are working\n",
    "!aws sts get-caller-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0a0b4df7-0074-40ac-9b10-ce517ad10d9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access /home/ec2-user/SageMaker/s3/newatlantis-raw-veba-db-prod/VDB_v8.1/: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls -l /home/ec2-user/SageMaker/s3/newatlantis-raw-veba-db-prod/VDB_v8.1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6fa3c57d-9103-4f63-926c-92dc34feb5a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-11-08 19:44:32     694354 GCA_000063505.1_genomic.fasta.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls s3://newatlantis-raw-veba-db-prod/VDB_v8.1/Classify/GTDB/skani/database/GCA/000/063/505/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f16d3a0d-6ab7-4eff-82a0-d40f9f9e1411",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assumed SageMaker role is arn:aws:iam::051581800907:role/service-role/AmazonSageMaker-ExecutionRole-20240617T145283\n"
     ]
    }
   ],
   "source": [
    "# This code sets up a SageMaker session and establishes an AWS Omics client\n",
    "\n",
    "boto_session = boto3.session.Session() # The boto session required to establish a connection to the AWS Omics client\n",
    "sagemaker_session = sagemaker.session.Session(boto_session) # This line sets up Amazon SageMaker resource interaction (training, model deployment, and experiement control)\n",
    "omics = boto3.client(\"omics\") # initializing the boto3 client specifically for the AWS Omics service\n",
    "\n",
    "REGION_NAME = sagemaker_session.boto_region_name # SageMaker resource region extraction (important that the resources being used for training tasks are created in the intended region)\n",
    "S3_BUCKET = sagemaker_session.default_bucket() # We initialize the default S3 bucket to store data related to SageMaker (model artifacts, datasets, etc..)\n",
    "\n",
    "EXPERIMENT_NAME = \"hyenaDNA-pretraining-v2\"\n",
    "\n",
    "SAGEMAKER_EXECUTION_ROLE = sagemaker.session.get_execution_role(sagemaker_session) # Retrieves the execution role assumed by SageMaker (the role that allows SageMaker to access other AWS resources on behalf of the user)\n",
    "print(f\"Assumed SageMaker role is {SAGEMAKER_EXECUTION_ROLE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a1d2ce43-0e72-4e5f-b1da-14dbab1c63a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref_store_id = \"8721910603\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "66483a09-650e-483b-89a9-7c236f5eecec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 50 references in the reference store.\n"
     ]
    }
   ],
   "source": [
    "response = omics.list_references(\n",
    "    referenceStoreId=ref_store_id\n",
    ")\n",
    "references = response.get('references', [])\n",
    "print(f\"There are {len(references)} references in the reference store.\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c52c863-2641-4fbd-94c9-5d9096ea2533",
   "metadata": {
    "tags": []
   },
   "source": [
    "existing_references = []\n",
    "for reference in references:\n",
    "    existing_references.append(reference['name'])\n",
    "    print(f\"Id: {reference['id']}   Name: {reference['name']}   Status: {reference['status']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c4d43c14-93ce-479d-afee-bf1b9edd424c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref_metadata = omics.get_reference_metadata(\n",
    "    id='6299798618',\n",
    "    referenceStoreId=ref_store_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "15e65d31-4704-4ae5-8399-f5241f61e384",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': {'totalParts': 1, 'partSize': 104857600, 'contentLength': 2396626},\n",
       " 'index': {'totalParts': 1, 'partSize': 104857600, 'contentLength': 28}}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_metadata['files']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7f258bf7-8e30-4a3d-874f-aba1511a0c24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref_01 = omics.get_reference(\n",
    "    id='6299798618',\n",
    "    referenceStoreId=ref_store_id,\n",
    "    partNumber = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "91dcdb2f-a1e7-402d-ac08-20accc978ff9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<botocore.response.StreamingBody at 0x7fdba21e9090>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref_01['payload']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d60a1e1-1598-49e2-8793-718c52c7bbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_store_id = \"4789217446\"  # replace with your sequence store id\n",
    "\n",
    "# This cell retrieves the metadata from the sequence store associated with the input ID\n",
    "\n",
    "seq_store_info = omics.get_sequence_store(id=seq_store_id) # Information includes storage location, access configurations, encryption settings, etc..\n",
    "s3_uri = seq_store_info[\"s3Access\"][\"s3Uri\"] # The path where the sequence data is stored (our data pointer)\n",
    "s3_arn = seq_store_info[\"s3Access\"][\"s3AccessPointArn\"] # Restricted access pointer for the data sequence store\n",
    "key_arn = seq_store_info[\"sseConfig\"][\"keyArn\"] # Encryption key for the sequence data in S3 bucket\n",
    "s3_uri, s3_arn, key_arn\n",
    "\n",
    "S3_DATA_URI = f\"{s3_uri}readSet/\"\n",
    "S3_DATA_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7bdd61-ebcb-4614-93a4-ca265afc0b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps({\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "            \"Sid\": \"S3DirectAccess\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": [\n",
    "                \"s3:GetObject\",\n",
    "                \"s3:ListBucket\"\n",
    "            ],\n",
    "            \"Resource\": \"*\",\n",
    "            \"Condition\": {\n",
    "                \"StringEquals\": {\n",
    "                    \"s3:DataAccessPointArn\": s3_arn\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"Sid\": \"DefaultSequenceStoreKMSDecrypt\",\n",
    "            \"Effect\": \"Allow\",\n",
    "            \"Action\": \"kms:Decrypt\",\n",
    "            \"Resource\": key_arn\n",
    "        }\n",
    "    ]\n",
    "}, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d7ed14-5882-4531-9712-734b65b2341f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pointer to the docker image for training config\n",
    "\n",
    "pytorch_image_uri = f\"763104351884.dkr.ecr.{REGION_NAME}.amazonaws.com/pytorch-training:2.2.0-gpu-py310-cu121-ubuntu20.04-sagemaker\"\n",
    "pytorch_image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f432942b-73b3-4cdb-aec8-9ecdde507bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this cell, we set up the parameters for a training job to fine tune the hyenaDNA model on our dataset of choice\n",
    "\n",
    "\n",
    "MODEL_ID = 'LongSafari/hyenadna-small-32k-seqlen-hf' # The path / id of the pre-trained model we seek to fine tune\n",
    "TRAINING_JOB_NAME = 'hyenaDNA-pretraining' # Our job identification label\n",
    "\n",
    "# Additional training parameters\n",
    "\n",
    "hyperparameters = {\n",
    "    \"species\" : \"mouse\",\n",
    "    \"epochs\": 150,\n",
    "    \"model_checkpoint\": MODEL_ID,\n",
    "    \"max_length\": 32_000,\n",
    "    \"batch_size\": 4,\n",
    "    \"learning_rate\": 6e-4,\n",
    "    \"weight_decay\" : 0.1,\n",
    "    \"log_level\" : \"INFO\",\n",
    "    \"log_interval\" : 100\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95480674-4e50-4183-a2a5-11f2107815a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The model performance metrics we want SageMaker to monitor\n",
    "\n",
    "metric_definitions = [\n",
    "    {\"Name\": \"epoch\", \"Regex\": \"Epoch: ([0-9.]*)\"},\n",
    "    {\"Name\": \"step\", \"Regex\": \"Step: ([0-9.]*)\"},\n",
    "    {\"Name\": \"train_loss\", \"Regex\": \"Train Loss: ([0-9.e-]*)\"},\n",
    "    {\"Name\": \"train_perplexity\", \"Regex\": \"Train Perplexity: ([0-9.e-]*)\"},\n",
    "    {\"Name\": \"eval_loss\", \"Regex\": \"Eval Average Loss: ([0-9.e-]*)\"},\n",
    "    {\"Name\": \"eval_perplexity\", \"Regex\": \"Eval Perplexity: ([0-9.e-]*)\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c719d163-cc40-4df7-9071-912e1d0c0543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyenaDNA model training config\n",
    "\n",
    "hyenaDNA_estimator = PyTorch(\n",
    "    base_job_name=TRAINING_JOB_NAME,                                      # The job name for organization we assigned earlier\n",
    "    entry_point=\"train_hf_accelerate.py\",                                 # The python script we will run for training\n",
    "    source_dir=\"scripts/\",                                                # Reference to directory with all necessary scripts for training\n",
    "    instance_type=\"ml.g5.12xlarge\",                                       # Compute instance type specification\n",
    "    instance_count=1,                                                     # Number of compute instances to use for training\n",
    "    image_uri=pytorch_image_uri,                                          # Inputting the pre-configured Docker image with PyTorch and CUDA dependencies installed\n",
    "    role=SAGEMAKER_EXECUTION_ROLE,                                        # Specifying the permission levels of SageMaker\n",
    "    hyperparameters=hyperparameters,                                      # Input the hyperparameter specifications we made earlier\n",
    "    metric_definitions=metric_definitions,                                # The custom pattern we made earlier specifying what performance metrics to monitor\n",
    "    sagemaker_session=sagemaker_session,                                  # The session established earlier\n",
    "    distribution={\"torch_distributed\": {\"enabled\": True}},                # Enabling distributed training (letting PyTorch tap into multiple compute resources in parallel for faster training)\n",
    "    tags=[{\"Key\": \"project\", \"Value\": \"genomics-model-pretraining\"}],     # Organization\n",
    "    keep_alive_period_in_seconds=1800,                                    # Allows us to terminate the training instance if the instance is running idle\n",
    "    tensorboard_output_config=tensorboard_output_config,                  # Specifies the TensorBoard logs to be synced to S3 for real-time training monitoring\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c9451c-a54b-4017-ad68-1d659f23182a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiating the SageMaker experiment run to tune the hyenaDNA model\n",
    "\n",
    "with Run(\n",
    "    experiment_name=EXPERIMENT_NAME,\n",
    "    sagemaker_session=sagemaker_session,\n",
    ") as run:\n",
    "    hyenaDNA_estimator.fit(\n",
    "        {\n",
    "            \"data\": TrainingInput(\n",
    "                s3_data=S3_DATA_URI, input_mode=\"File\"                # Here the model training is officially launched! :D\n",
    "            ),\n",
    "        },\n",
    "        wait=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b73c16-2e61-4e30-a3d9-768b0a409b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull the latest training job's ID for ease of reference\n",
    "\n",
    "training_job_name = hyenaDNA_estimator.latest_training_job.name\n",
    "training_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303e298c-536e-439e-a6be-75d4ec8d0fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_profile = \"shamika\" # replace with your sagemaker studio profile name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e18ac80-4315-4a57-ac8b-e2b356c8dcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launches TensorBoard in SageMaker\n",
    "\n",
    "from sagemaker.interactive_apps.tensorboard import TensorBoardApp\n",
    "\n",
    "with open(\"/opt/ml/metadata/resource-metadata.json\", \"r\") as f:\n",
    "    app_metadata = json.loads(f.read())\n",
    "    sm_user_profile_name = app_metadata[\"SpaceName\"]\n",
    "    sm_domain_id = app_metadata[\"DomainId\"]\n",
    "\n",
    "tb_app = TensorBoardApp(REGION_NAME)\n",
    "tb_app.get_app_url(\n",
    "    training_job_name=training_job_name,\n",
    "    create_presigned_domain_url=True,\n",
    "    domain_id=sm_domain_id,\n",
    "    user_profile_name=user_profile,\n",
    "    open_in_default_web_browser=False,\n",
    "    optional_create_presigned_url_kwargs={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2f2079-14fd-454b-9914-237a93867d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "from sagemaker.estimator import Estimator\n",
    "\n",
    "training_job_name = \"hyenaDNA-pretraining-2024-04-06-06-23-26-412\"\n",
    "#attached_estimator = Estimator.attach(training_job_name)\n",
    "\n",
    "model_data = attached_estimator.model_data\n",
    "model_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88fa8bda-b2c2-43a7-8227-7e4bfa237f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the model to create a real-time endpoint\n",
    "\n",
    "endpoint_name = 'hyenaDNA-pretrained-mouse-ep'                 # The name reference for the endpoint we will use to access the model's real-time predictions\n",
    "pytorch_deployment_uri = f\"763104351884.dkr.ecr.{REGION_NAME}.amazonaws.com/pytorch-inference:2.2.0-gpu-py310-cu118-ubuntu20.04-sagemaker\"\n",
    "\n",
    "\n",
    "# Below we use the endpoint definition and the loaded trained model artifacts to intialize / prepare our PyTorchModel for deployment!\n",
    "hyenaDNAModel = PyTorchModel(\n",
    "    model_data=model_data,\n",
    "    role=SAGEMAKER_EXECUTION_ROLE,\n",
    "    image_uri=pytorch_deployment_uri,\n",
    "    entry_point=\"inference.py\",\n",
    "    source_dir=\"scripts/\",\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    name=endpoint_name,\n",
    "    env = {\n",
    "        'MMS_MAX_REQUEST_SIZE': '2000000000',\n",
    "        'MMS_MAX_RESPONSE_SIZE': '2000000000',\n",
    "        'MMS_DEFAULT_RESPONSE_TIMEOUT': '900',\n",
    "        'TS_MAX_RESPONSE_SIZE':'2000000000',\n",
    "        'TS_MAX_REQUEST_SIZE':'2000000000',\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a7595a-9c99-4bed-8017-2de6ac0a1a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#real_time_endpoint_name = \"hyenaDNA-mouse-pretrained-real-ep\"\n",
    "env = {\n",
    "    'SAGEMAKER_MODEL_SERVER_TIMEOUT':'7200',\n",
    "    'TS_MAX_RESPONSE_SIZE':'2000000000',\n",
    "    'TS_MAX_REQUEST_SIZE':'2000000000',\n",
    "    'MMS_MAX_RESPONSE_SIZE':'2000000000',\n",
    "    'MMS_MAX_REQUEST_SIZE':'2000000000'\n",
    "}\n",
    "\n",
    "# deploy the endpoint\n",
    "realtime_predictor = hyenaDNAModel.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g5.8xlarge\",\n",
    "    endpoint_name=endpoint_name,\n",
    "    env=env,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7316e7fe-f3a9-4e49-9a37-3436d8ab9704",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loading a sample of genomic data\n",
    "\n",
    "import json\n",
    "sample_genome_data = []\n",
    "with open(\"./sample_mouse_data.json\") as file:\n",
    "    for line in file:\n",
    "        sample_genome_data.append(json.loads(line))\n",
    "len(sample_genome_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08a796e-2472-4a84-a74b-346f15ec9957",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sample_genome_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe547a83-51b3-46e7-8b6c-7e12d6526b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Retrieves the embedding output of the loaded data on the deployed model\n",
    "\n",
    "from sagemaker.deserializers import JSONDeserializer\n",
    "from sagemaker.serializers import JSONSerializer\n",
    "\n",
    "\n",
    "data = [sample_genome_data[0]]\n",
    "realtime_predictor.serializer = JSONSerializer()\n",
    "realtime_predictor.deserializer = JSONDeserializer()\n",
    "embeddings = realtime_predictor.predict(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902ed8a6-5ac6-487e-9c24-3efc3db855b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06938fbc-8d87-4b8a-b2e9-6518a1d2d6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Terminating the endpoint access, freeing up resources and stopping SageMaker charges\n",
    "\n",
    "realtime_predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
